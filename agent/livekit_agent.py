import asyncio
import time
import numpy as np

from livekit.agents import JobContext, WorkerOptions, cli, AutoSubscribe
from livekit.rtc import (
    AudioSource,
    LocalAudioTrack,
    AudioFrame,
    AudioStream,
    TrackKind,
)

from agent.stt import WhisperSTT
from agent.llm import GroqAgent
from agent.models.edge_tts import EdgeTTS
from agent.config import LIVEKIT_URL
from agent.memory import ConversationMemory
from agent.intent import detect_intent, Intent
from agent.tools import search_products, track_order


TARGET_SR = 16000
CHANNELS = 1

# ---- Speech detection tuning ----
SPEECH_RMS = 900
SILENCE_FRAMES = 8
MIN_UTTERANCE_BYTES = TARGET_SR * 2  # ~1 second


def resample_48k_to_16k(pcm_48k: bytes) -> bytes:
    audio = np.frombuffer(pcm_48k, dtype=np.int16)
    return audio[::3].tobytes()


async def entrypoint(ctx: JobContext):
    print("ðŸš€ Agent starting")
    await ctx.connect(auto_subscribe=AutoSubscribe.AUDIO_ONLY)
    print("ðŸŽ¤ Connected to room")

    # ---- Publish agent audio ----
    audio_source = AudioSource(TARGET_SR, CHANNELS)
    agent_track = LocalAudioTrack.create_audio_track("agent-audio", audio_source)
    await ctx.room.local_participant.publish_track(agent_track)
    print("ðŸ”Š Agent audio track published")

    # ---- Core components ----
    stt = WhisperSTT()
    llm = GroqAgent()
    tts = EdgeTTS()
    memory = ConversationMemory()

    agent_speaking = asyncio.Event()
    stop_tts = asyncio.Event()

    async def handle_audio(track):
        buffer_48k = bytearray()
        utterance_16k = bytearray()
        silence_count = 0
        in_speech = False

        async for event in AudioStream(track):
            if not hasattr(event, "frame"):
                continue

            frame: AudioFrame = event.frame
            buffer_48k.extend(frame.data)

            # wait for ~1 sec of 48k audio
            if len(buffer_48k) < 48000 * 2:
                continue

            pcm_48k = bytes(buffer_48k)
            buffer_48k.clear()

            pcm_16k = resample_48k_to_16k(pcm_48k)
            samples = np.frombuffer(pcm_16k, dtype=np.int16)

            rms = int(np.sqrt(np.mean(samples.astype(np.float32) ** 2)))
            print("ðŸŽš RMS:", rms)

            # ---- BARGE-IN ----
            if agent_speaking.is_set() and rms >= SPEECH_RMS:
                print("â›” Barge-in detected")
                stop_tts.set()
                agent_speaking.clear()

            if rms >= SPEECH_RMS:
                in_speech = True
                silence_count = 0
                utterance_16k.extend(pcm_16k)
                continue

            if in_speech:
                silence_count += 1
                utterance_16k.extend(pcm_16k)

                if silence_count >= SILENCE_FRAMES:
                    in_speech = False

                    if len(utterance_16k) < MIN_UTTERANCE_BYTES:
                        utterance_16k.clear()
                        continue

                    turn_start = time.perf_counter()

                    # ---- STT ----
                    stt_start = time.perf_counter()
                    text = await stt.transcribe(bytes(utterance_16k))
                    stt_time = (time.perf_counter() - stt_start) * 1000
                    utterance_16k.clear()

                    if not text:
                        continue

                    print("ðŸ§  STT:", text)
                    memory.add_user(text)

                    # ---- INTENT ROUTING ----
                    intent = detect_intent(text)
                    print("ðŸ§­ Intent:", intent)

                    if intent == Intent.PRODUCT_SEARCH:
                        products = search_products(text)
                        reply = "Here are some options:\n" + "\n".join(
                            f"- {p['name']} for â‚¹{p['price']}"
                            for p in products
                        )

                    elif intent == Intent.ORDER_TRACKING:
                        order = track_order("ORD123")
                        reply = (
                            f"Your order {order['order_id']} is "
                            f"{order['status']}. Expected delivery is "
                            f"{order['expected_delivery']}."
                        )

                    else:
                        llm_start = time.perf_counter()
                        reply = await llm.reply(text, memory)
                        llm_time = (time.perf_counter() - llm_start) * 1000

                    memory.add_assistant(reply)
                    print("ðŸ¤– Reply:", reply)

                    # ---- TTS ----
                    agent_speaking.set()
                    stop_tts.clear()

                    tts_start = time.perf_counter()
                    audio_bytes = await tts.synthesize(reply)
                    tts_time = (time.perf_counter() - tts_start) * 1000

                    out_samples = np.frombuffer(audio_bytes, dtype=np.int16)
                    frame_size = 320  # 20ms

                    for i in range(0, len(out_samples), frame_size):
                        if stop_tts.is_set():
                            print("ðŸ›‘ TTS interrupted")
                            break

                        chunk = out_samples[i:i + frame_size]
                        if len(chunk) < frame_size:
                            break

                        await audio_source.capture_frame(
                            AudioFrame(
                                data=chunk.tobytes(),
                                sample_rate=TARGET_SR,
                                num_channels=1,
                                samples_per_channel=frame_size,
                            )
                        )
                        await asyncio.sleep(0.02)

                    # ---- MULTI-FRAME SILENCE FLUSH (CRACKLE FIX) ----
                    silence = np.zeros(frame_size, dtype=np.int16)
                    for _ in range(12):  # ~240ms silence
                        await audio_source.capture_frame(
                            AudioFrame(
                                data=silence.tobytes(),
                                sample_rate=TARGET_SR,
                                num_channels=1,
                                samples_per_channel=frame_size,
                            )
                        )
                        await asyncio.sleep(0.02)

                    agent_speaking.clear()

                    total = (time.perf_counter() - turn_start) * 1000
                    print(
                        f"\nðŸ“Š METRICS | STT {stt_time:.0f}ms | "
                        f"TTS {tts_time:.0f}ms | TOTAL {total:.0f}ms\n"
                    )

    def attach(track):
        if track.kind == TrackKind.KIND_AUDIO:
            asyncio.create_task(handle_audio(track))

    @ctx.room.on("track_subscribed")
    def on_track(track, publication, participant):
        attach(track)

    for p in ctx.room.remote_participants.values():
        for pub in p.track_publications.values():
            if pub.track:
                attach(pub.track)

    try:
        while True:
            await asyncio.sleep(1)
    except asyncio.CancelledError:
        print("ðŸ›‘ Agent shutdown cleanly")


def main():
    cli.run_app(
        WorkerOptions(
            entrypoint_fnc=entrypoint,
            ws_url=LIVEKIT_URL,
        )
    )


if __name__ == "__main__":
    main()
